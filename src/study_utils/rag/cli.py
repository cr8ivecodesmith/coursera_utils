"""Command-line entry points for the Study RAG workspace."""

from __future__ import annotations

import argparse
import logging
import sys
from pathlib import Path
from typing import Sequence

from rich.console import Console

from . import chat as chat_mod
from . import config as config_mod
from . import data_dir
from . import doctor as doctor_mod
from . import ingest as ingest_mod
from . import session as session_mod
from . import vector_store
from study_utils.core import logging as core_logging


LOGGER = logging.getLogger("study_utils.rag.cli")


def _build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        prog="study rag",
        description="Manage Study RAG configuration and resources.",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable debug logging and verbose console diagnostics.",
    )
    parser.add_argument(
        "--log-level",
        choices=("DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"),
        help="Override rag.log file level (defaults to config).",
    )
    subparsers = parser.add_subparsers(dest="command", required=True)

    config_parser = subparsers.add_parser(
        "config",
        help="Manage Study RAG configuration files.",
    )
    _build_config_subcommands(config_parser)

    ingest_parser = subparsers.add_parser(
        "ingest",
        help="Ingest study materials into a named vector database.",
    )
    ingest_parser.add_argument(
        "--name",
        required=True,
        help="Logical name for the vector database (letters, numbers, -,_).",
    )
    ingest_parser.add_argument(
        "--force",
        action="store_true",
        help="Overwrite an existing vector database with the same name.",
    )
    ingest_parser.add_argument(
        "paths",
        nargs="+",
        help="Files or directories to ingest (recursively when directories).",
    )

    subparsers.add_parser(
        "list",
        help="List available vector databases.",
    )

    inspect_parser = subparsers.add_parser(
        "inspect",
        help="Show manifest details for a vector database.",
    )
    inspect_parser.add_argument(
        "--name",
        required=True,
        help="Name of the vector database to inspect.",
    )

    delete_parser = subparsers.add_parser(
        "delete",
        help="Delete a vector database from the data directory.",
    )
    delete_parser.add_argument(
        "--name",
        required=True,
        help="Name of the vector database to remove.",
    )

    export_parser = subparsers.add_parser(
        "export",
        help="Export a vector database as a portable archive.",
    )
    export_parser.add_argument(
        "--name",
        required=True,
        help="Name of the vector database to export.",
    )
    export_parser.add_argument(
        "--out",
        required=True,
        help="Destination zip archive path.",
    )

    import_parser = subparsers.add_parser(
        "import",
        help="Import a vector database from an archive.",
    )
    import_parser.add_argument(
        "--name",
        required=True,
        help="Target name for the imported vector database.",
    )
    import_parser.add_argument(
        "--archive",
        required=True,
        help="Source zip archive path.",
    )
    import_parser.add_argument(
        "--force",
        action="store_true",
        help="Overwrite an existing database with the same name.",
    )

    subparsers.add_parser(
        "doctor",
        help="Inspect the Study RAG environment for common issues.",
    )

    chat_parser = subparsers.add_parser(
        "chat",
        help="Open an interactive Study RAG chat session.",
    )
    chat_parser.add_argument(
        "--db",
        dest="dbs",
        action="append",
        default=[],
        help="Vector database to attach (repeatable).",
    )
    chat_parser.add_argument(
        "--resume",
        help="Session ID to resume (ignores --db unless adding new stores).",
    )
    chat_parser.add_argument(
        "--question",
        help="Send a single prompt and print the response before exiting.",
    )

    return parser


def _build_config_subcommands(parent: argparse.ArgumentParser) -> None:
    subparsers = parent.add_subparsers(dest="config_command", required=True)

    init_parser = subparsers.add_parser(
        "init",
        help="Write the default configuration template.",
    )
    init_parser.add_argument(
        "--path",
        type=str,
        help=(
            "Optional destination for the config TOML (defaults to data home)."
        ),
    )
    init_parser.add_argument(
        "--force",
        action="store_true",
        help="Overwrite an existing config file if present.",
    )

    validate_parser = subparsers.add_parser(
        "validate",
        help="Validate the active configuration file.",
    )
    validate_parser.add_argument(
        "--path",
        type=str,
        help="Path to the config TOML (defaults to resolved data home).",
    )
    validate_parser.add_argument(
        "--quiet",
        action="store_true",
        help="Suppress success output; errors still print to stderr.",
    )

    path_parser = subparsers.add_parser(
        "path",
        help="Print the resolved config path.",
    )
    path_parser.add_argument(
        "--path",
        type=str,
        help="Optional path override to resolve/normalise.",
    )


def _to_path(value: str | None) -> Path | None:
    if value is None:
        return None
    return Path(value).expanduser().resolve()


def _bootstrap_logging(args: argparse.Namespace) -> None:
    level_override = getattr(args, "log_level", None)
    verbose_flag = bool(getattr(args, "verbose", False))
    cached_config: config_mod.RagConfig | None = None
    config_error: str | None = None

    if args.command != "config":
        try:
            cached_config = config_mod.load_config()
        except config_mod.ConfigError as exc:
            config_error = str(exc)

    if cached_config is not None:
        if level_override is None:
            level_override = cached_config.logging.level
        if not verbose_flag:
            verbose_flag = cached_config.logging.verbose
        setattr(args, "_bootstrap_config", cached_config)

    level_value = (level_override or "INFO").upper()
    logger, log_path = core_logging.configure_logger(
        "study_utils.rag",
        log_dir=data_dir.logs_dir(),
        level=level_value,
        verbose=verbose_flag,
        filename="rag.log",
    )
    logger.debug(
        "Configured logging",
        extra={
            "event": "logging.configured",
            "command": args.command,
            "level": level_value,
            "verbose": verbose_flag,
            "log_path": log_path,
        },
    )
    if config_error is not None:
        logger.debug(
            "Failed to preload config for logging",
            extra={
                "event": "logging.config_error",
                "command": args.command,
                "reason": config_error,
            },
        )


def _load_config_cached(args: argparse.Namespace) -> config_mod.RagConfig:
    cached = getattr(args, "_bootstrap_config", None)
    if cached is not None:
        return cached
    cfg = config_mod.load_config()
    setattr(args, "_bootstrap_config", cfg)
    return cfg


def _handle_config(args: argparse.Namespace) -> int:
    command = args.config_command
    LOGGER.info(
        "Handling config command",
        extra={"event": "config.dispatch", "subcommand": command},
    )
    if command == "init":
        return _handle_config_init(args)
    if command == "validate":
        return _handle_config_validate(args)
    if command == "path":
        return _handle_config_path(args)
    raise RuntimeError(f"Unhandled config command: {command}")


def _handle_config_init(args: argparse.Namespace) -> int:
    explicit_path = _to_path(args.path)
    LOGGER.info(
        "Writing config template",
        extra={
            "event": "config.init.start",
            "explicit_path": explicit_path,
            "force": args.force,
        },
    )
    try:
        target = config_mod.resolve_config_path(explicit_path=explicit_path)
        config_mod.write_template(target, overwrite=args.force)
    except config_mod.ConfigError as exc:
        _print_error(
            str(exc),
            extra={
                "event": "config.init.error",
                "explicit_path": explicit_path,
                "force": args.force,
            },
        )
        return 2
    LOGGER.info(
        "Config template ready",
        extra={
            "event": "config.init.complete",
            "path": target,
            "overwritten": args.force,
        },
    )
    print(f"Wrote config template to {target}")
    return 0


def _handle_config_validate(args: argparse.Namespace) -> int:
    explicit_path = _to_path(args.path)
    LOGGER.info(
        "Validating configuration",
        extra={
            "event": "config.validate.start",
            "explicit_path": explicit_path,
            "quiet": bool(args.quiet),
        },
    )
    try:
        cfg = config_mod.load_config(explicit_path=explicit_path)
    except config_mod.ConfigError as exc:
        _print_error(
            str(exc),
            extra={
                "event": "config.validate.error",
                "explicit_path": explicit_path,
            },
        )
        return 2
    if not args.quiet:
        print("Configuration OK")
        print(f"  data_home: {cfg.data_home}")
        provider = cfg.providers.openai
        print(f"  chat_model: {provider.chat_model}")
        print(f"  embedding_model: {provider.embedding_model}")
        print(f"  chunk_tokens: {cfg.ingestion.chunking.tokens_per_chunk}")
    LOGGER.info(
        "Configuration validation succeeded",
        extra={
            "event": "config.validate.complete",
            "explicit_path": explicit_path,
            "data_home": cfg.data_home,
        },
    )
    return 0


def _handle_config_path(args: argparse.Namespace) -> int:
    explicit_path = _to_path(args.path)
    LOGGER.info(
        "Resolving config path",
        extra={
            "event": "config.path.start",
            "explicit_path": explicit_path,
        },
    )
    try:
        path = config_mod.resolve_config_path(explicit_path=explicit_path)
    except config_mod.ConfigError as exc:
        _print_error(
            str(exc),
            extra={
                "event": "config.path.error",
                "explicit_path": explicit_path,
            },
        )
        return 2
    LOGGER.info(
        "Resolved config path",
        extra={
            "event": "config.path.complete",
            "explicit_path": explicit_path,
            "resolved_path": path,
        },
    )
    print(path)
    return 0


def _handle_ingest(args: argparse.Namespace) -> int:
    LOGGER.info(
        "Starting ingest",
        extra={
            "event": "ingest.start",
            "db_name": args.name,
            "force": bool(args.force),
            "paths": list(args.paths),
        },
    )
    try:
        cfg = _load_config_cached(args)
    except config_mod.ConfigError as exc:
        _print_error(
            str(exc),
            extra={"event": "ingest.config_error", "db_name": args.name},
        )
        return 2

    repo = _build_repository()
    backend = _build_backend()
    input_paths = [Path(p) for p in args.paths]
    try:
        embedder = _build_embedder(cfg)
        chunker = _build_chunker(cfg)
        report = ingest_mod.ingest_sources(
            args.name,
            inputs=input_paths,
            repository=repo,
            backend=backend,
            embedder=embedder,
            chunker=chunker,
            embedding_provider=cfg.providers.default,
            embedding_model=_select_embedding_model(cfg),
            dedupe=_build_dedupe(cfg),
            chunking=_build_chunking(cfg),
            overwrite=args.force,
        )
    except vector_store.VectorStoreError as exc:
        _print_error(
            str(exc),
            extra={"event": "ingest.error", "db_name": args.name},
        )
        return 2
    except RuntimeError as exc:
        _print_error(
            str(exc),
            extra={"event": "ingest.runtime_error", "db_name": args.name},
        )
        return 2

    manifest_path = repo.manifest_path(report.name)
    LOGGER.info(
        "Ingest finished",
        extra={
            "event": "ingest.complete",
            "db_name": report.name,
            "documents_ingested": report.documents_ingested,
            "documents_skipped": report.documents_skipped,
            "chunks_ingested": report.chunks_ingested,
            "manifest": manifest_path,
        },
    )
    _print_ingest_report(report, manifest_path)
    return 0


def _handle_list(args: argparse.Namespace) -> int:  # noqa: ARG001
    repo = _build_repository()
    LOGGER.info("Listing vector stores", extra={"event": "list.start"})
    manifests = repo.list_manifests()
    if not manifests:
        LOGGER.info(
            "No vector stores found",
            extra={"event": "list.complete", "count": 0},
        )
        print("No vector databases found.")
        return 0
    name_width = max(len(item.name) for item in manifests)
    print("Name".ljust(name_width), "Created", "Docs", "Chunks", "Model")
    for manifest in manifests:
        docs = len(manifest.documents)
        line = "{name:<{width}} {created} {docs:>4} {chunks:>6} {model}".format(
            name=manifest.name,
            width=name_width,
            created=manifest.created_at,
            docs=docs,
            chunks=manifest.total_chunks,
            model=manifest.embedding.model,
        )
        print(line)
    LOGGER.info(
        "Listed vector stores",
        extra={"event": "list.complete", "count": len(manifests)},
    )
    return 0


def _handle_inspect(args: argparse.Namespace) -> int:
    repo = _build_repository()
    LOGGER.info(
        "Inspecting vector store",
        extra={"event": "inspect.start", "db_name": args.name},
    )
    try:
        manifest = repo.load_manifest(args.name)
    except vector_store.VectorStoreError as exc:
        _print_error(
            str(exc),
            extra={"event": "inspect.error", "db_name": args.name},
        )
        return 2
    LOGGER.info(
        "Inspect complete",
        extra={
            "event": "inspect.complete",
            "db_name": manifest.name,
            "documents": len(manifest.documents),
            "chunks": manifest.total_chunks,
        },
    )
    _print_manifest_details(manifest)
    return 0


def _handle_delete(args: argparse.Namespace) -> int:
    repo = _build_repository()
    LOGGER.info(
        "Deleting vector store",
        extra={"event": "delete.start", "db_name": args.name},
    )
    try:
        repo.delete(args.name)
    except vector_store.VectorStoreError as exc:
        _print_error(
            str(exc),
            extra={"event": "delete.error", "db_name": args.name},
        )
        return 2
    LOGGER.info(
        "Vector store deleted",
        extra={"event": "delete.complete", "db_name": args.name},
    )
    print(f"Deleted vector database '{args.name}'.")
    return 0


def _handle_export(args: argparse.Namespace) -> int:
    repo = _build_repository()
    destination = Path(args.out).expanduser().resolve()
    LOGGER.info(
        "Exporting vector store",
        extra={
            "event": "export.start",
            "db_name": args.name,
            "destination": destination,
        },
    )
    try:
        repo.export_store(args.name, destination)
    except vector_store.VectorStoreError as exc:
        _print_error(
            str(exc),
            extra={
                "event": "export.error",
                "db_name": args.name,
                "destination": destination,
            },
        )
        return 2
    print(
        "Exported vector database '{0}' to {1}.".format(
            args.name,
            destination,
        )
    )
    LOGGER.info(
        "Export completed",
        extra={
            "event": "export.complete",
            "db_name": args.name,
            "destination": destination,
        },
    )
    return 0


def _handle_import(args: argparse.Namespace) -> int:
    repo = _build_repository()
    archive = Path(args.archive).expanduser().resolve()
    LOGGER.info(
        "Importing vector store",
        extra={
            "event": "import.start",
            "db_name": args.name,
            "archive": archive,
            "force": bool(args.force),
        },
    )
    try:
        manifest = repo.import_store(
            args.name,
            archive,
            overwrite=args.force,
        )
    except vector_store.VectorStoreError as exc:
        _print_error(
            str(exc),
            extra={
                "event": "import.error",
                "db_name": args.name,
                "archive": archive,
                "force": bool(args.force),
            },
        )
        return 2
    print(
        "Imported vector database '{0}' ({1} chunks).".format(
            manifest.name,
            manifest.total_chunks,
        )
    )
    LOGGER.info(
        "Import completed",
        extra={
            "event": "import.complete",
            "db_name": manifest.name,
            "chunks": manifest.total_chunks,
        },
    )
    return 0


def _handle_doctor(args: argparse.Namespace) -> int:  # noqa: ARG001
    LOGGER.info("Running doctor", extra={"event": "doctor.start"})
    report = doctor_mod.generate_report()
    output = doctor_mod.format_report(report)
    print(output)
    status = "ok" if not doctor_mod.has_errors(report) else "issues"
    LOGGER.info(
        "Doctor complete",
        extra={"event": "doctor.complete", "status": status},
    )
    return 0 if status == "ok" else 1


def _handle_chat(args: argparse.Namespace) -> int:
    LOGGER.info(
        "Preparing chat runtime",
        extra={
            "event": "chat.start",
            "resume": bool(args.resume),
            "dbs": list(args.dbs or []),
            "question": bool(args.question),
        },
    )
    try:
        cfg = _load_config_cached(args)
    except config_mod.ConfigError as exc:
        _print_error(
            str(exc),
            extra={"event": "chat.config_error"},
        )
        return 2

    try:
        embedder = _build_embedder(cfg)
    except vector_store.VectorStoreError as exc:
        _print_error(
            str(exc),
            extra={"event": "chat.embedder_error"},
        )
        return 2

    try:
        chat_client = _build_chat_client(cfg)
    except RuntimeError as exc:
        _print_error(
            str(exc),
            extra={"event": "chat.client_error"},
        )
        return 2

    repo = _build_repository()
    sessions_root = data_dir.sessions_dir()
    store = session_mod.SessionStore(sessions_root)
    runtime = chat_mod.ChatRuntime(
        config=cfg,
        repository=repo,
        session_store=store,
        embedder=embedder,
        chat_client=chat_client,
    )

    dbs = tuple(args.dbs or [])
    try:
        sess = runtime.prepare_session(
            resume_id=args.resume,
            vector_dbs=dbs,
        )
    except (
        chat_mod.ChatError,
        session_mod.SessionError,
        vector_store.VectorStoreError,
    ) as exc:
        _print_error(
            str(exc),
            extra={
                "event": "chat.prepare_error",
                "resume": args.resume,
                "dbs": list(dbs),
            },
        )
        return 2
    LOGGER.info(
        "Chat session prepared",
        extra={
            "event": "chat.session",
            "session_id": sess.session_id,
            "resume": bool(args.resume),
            "dbs": list(sess.vector_dbs),
        },
    )

    question = args.question
    if question:
        try:
            answer = runtime.ask(sess, question)
        except chat_mod.ChatError as exc:
            _print_error(
                str(exc),
                extra={
                    "event": "chat.question.error",
                    "session_id": sess.session_id,
                },
            )
            return 2
        LOGGER.info(
            "Answered question",
            extra={
                "event": "chat.question.complete",
                "session_id": answer.session_id,
                "prompt_chars": len(question),
                "context_count": len(answer.contexts),
            },
        )
        _print_chat_answer(answer)
        return 0

    console = Console()
    LOGGER.info(
        "Starting interactive chat",
        extra={
            "event": "chat.interactive.start",
            "session_id": sess.session_id,
        },
    )
    runtime.interactive_loop(sess, console=console)
    LOGGER.info(
        "Interactive chat finished",
        extra={
            "event": "chat.interactive.complete",
            "session_id": sess.session_id,
        },
    )
    return 0


def _build_repository() -> vector_store.VectorStoreRepository:
    root = data_dir.vector_db_dir()
    return vector_store.VectorStoreRepository(root)


def _build_backend() -> vector_store.VectorStoreBackend:
    return vector_store.FaissVectorStoreBackend()


def _build_embedder(cfg: config_mod.RagConfig) -> ingest_mod.EmbeddingClient:
    provider = cfg.providers.default.lower()
    if provider != "openai":
        raise vector_store.VectorStoreError(
            "Only the 'openai' provider is supported for embeddings."
        )
    openai_cfg = cfg.providers.openai
    return ingest_mod.OpenAIEmbeddingClient(
        model=openai_cfg.embedding_model,
        api_base=openai_cfg.api_base,
        request_timeout=openai_cfg.request_timeout_seconds,
    )


def _build_chat_client(cfg: config_mod.RagConfig) -> chat_mod.ChatClient:
    openai_cfg = cfg.providers.openai
    return chat_mod.OpenAIChatClient(
        model=openai_cfg.chat_model,
        temperature=openai_cfg.temperature,
        max_output_tokens=cfg.chat.response_tokens,
        request_timeout=openai_cfg.request_timeout_seconds,
        api_base=openai_cfg.api_base,
    )


def _build_chunker(cfg: config_mod.RagConfig) -> ingest_mod.TextChunker:
    chunk_cfg = cfg.ingestion.chunking
    return ingest_mod.TextChunker(
        tokenizer=chunk_cfg.tokenizer,
        encoding=chunk_cfg.encoding,
        tokens_per_chunk=chunk_cfg.tokens_per_chunk,
        token_overlap=chunk_cfg.token_overlap,
        fallback_delimiter=chunk_cfg.fallback_delimiter,
    )


def _build_dedupe(cfg: config_mod.RagConfig) -> vector_store.DedupMetadata:
    dedupe_cfg = cfg.ingestion.dedupe
    return vector_store.DedupMetadata(
        strategy=dedupe_cfg.strategy,
        checksum_algorithm=dedupe_cfg.checksum_algorithm,
    )


def _build_chunking(cfg: config_mod.RagConfig) -> vector_store.ChunkingMetadata:
    chunk_cfg = cfg.ingestion.chunking
    return vector_store.ChunkingMetadata(
        tokenizer=chunk_cfg.tokenizer,
        encoding=chunk_cfg.encoding,
        tokens_per_chunk=chunk_cfg.tokens_per_chunk,
        token_overlap=chunk_cfg.token_overlap,
        fallback_delimiter=chunk_cfg.fallback_delimiter,
    )


def _select_embedding_model(cfg: config_mod.RagConfig) -> str:
    provider = cfg.providers.default.lower()
    if provider == "openai":
        return cfg.providers.openai.embedding_model
    raise vector_store.VectorStoreError(
        f"Unknown embedding provider '{cfg.providers.default}'."
    )


def _print_ingest_report(
    report: ingest_mod.IngestionReport,
    manifest_path: Path,
) -> None:
    print(f"Vector database '{report.name}' ready.")
    print(f"  documents ingested: {report.documents_ingested}")
    print(f"  documents skipped: {report.documents_skipped}")
    print(f"  chunks ingested: {report.chunks_ingested}")
    print(f"  manifest: {manifest_path}")


def _print_manifest_details(manifest: vector_store.VectorStoreManifest) -> None:
    print(f"Name: {manifest.name}")
    print(f"Created: {manifest.created_at}")
    print(f"Updated: {manifest.updated_at}")
    print(f"Schema: {manifest.schema_version}")
    print("Embedding:")
    print(f"  provider: {manifest.embedding.provider}")
    print(f"  model: {manifest.embedding.model}")
    print(f"  dimension: {manifest.embedding.dimension}")
    print("Chunking:")
    print(f"  tokenizer: {manifest.chunking.tokenizer}")
    print(f"  encoding: {manifest.chunking.encoding}")
    print(f"  tokens_per_chunk: {manifest.chunking.tokens_per_chunk}")
    print(f"  token_overlap: {manifest.chunking.token_overlap}")
    print(f"  fallback_delimiter: {manifest.chunking.fallback_delimiter}")
    print("Deduplication:")
    print(f"  strategy: {manifest.dedupe.strategy}")
    print(f"  checksum_algorithm: {manifest.dedupe.checksum_algorithm}")
    print(f"Documents: {len(manifest.documents)}")
    if not manifest.documents:
        return
    for doc in manifest.documents:
        print(f"- {doc.source_path}")
        print(f"  checksum: {doc.checksum}")
        print(f"  size_bytes: {doc.size_bytes}")
        print(f"  chunks: {doc.chunk_count}")


def _print_chat_answer(answer: chat_mod.ChatAnswer) -> None:
    print(answer.response)
    if not answer.contexts:
        print("No retrieval context met the score threshold.")
        return
    print("Context snippets:")
    for item in answer.contexts:
        source = item.metadata.get("source_path", "unknown")
        chunk = item.metadata.get("chunk_index")
        chunk_info = f" (chunk {chunk})" if chunk is not None else ""
        print(
            "- {db}: {source}{chunk_info} (score {score:.3f})".format(
                db=item.db_name,
                source=source,
                chunk_info=chunk_info,
                score=item.score,
            )
        )


def main(argv: Sequence[str] | None = None) -> int:
    parser = _build_parser()
    try:
        args = parser.parse_args(list(argv) if argv is not None else None)
    except SystemExit as exc:  # pragma: no cover - argparse already handles
        return int(exc.code)

    _bootstrap_logging(args)

    handlers = {
        "config": _handle_config,
        "ingest": _handle_ingest,
        "list": _handle_list,
        "inspect": _handle_inspect,
        "delete": _handle_delete,
        "export": _handle_export,
        "import": _handle_import,
        "doctor": _handle_doctor,
        "chat": _handle_chat,
    }
    handler = handlers.get(args.command)
    if handler is None:
        LOGGER.error(
            "Unhandled command",
            extra={"event": "cli.unknown_command", "command": args.command},
        )
        parser.error("Command not implemented yet.")
        return 2
    LOGGER.info(
        "Dispatching command",
        extra={"event": "cli.dispatch", "command": args.command},
    )
    exit_code = handler(args)
    LOGGER.info(
        "Command completed",
        extra={
            "event": "cli.complete",
            "command": args.command,
            "exit_code": exit_code,
        },
    )
    return exit_code


def _print_error(
    message: str,
    *,
    extra: dict[str, object] | None = None,
) -> None:
    payload = {"event": "cli.error"}
    if extra:
        payload.update(extra)
    LOGGER.error(
        message,
        extra=payload,
    )
    sys.stderr.write(message + "\n")


if __name__ == "__main__":  # pragma: no cover
    sys.exit(main())
